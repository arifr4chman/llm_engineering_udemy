{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ollama' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Creation**: Generative AI can be used to generate high-quality content such as articles, social media posts, product descriptions, and more. This can help businesses save time and resources while maintaining consistency in their content.\n",
      "2. **Marketing Automation**: Generative AI can be used to automate marketing campaigns by generating personalized emails, ads, and promotional materials based on customer data and behavior.\n",
      "3. **Product Design and Development**: Generative AI can be used to design new products, such as furniture, electronics, and other consumer goods. It can also be used to optimize product designs for better performance and aesthetics.\n",
      "4. **Supply Chain Optimization**: Generative AI can be used to analyze supply chain data and generate predictions about future demand, helping businesses optimize their inventory management and logistics.\n",
      "5. **Customer Service**: Generative AI-powered chatbots can be used to provide 24/7 customer support, answering common questions and routing complex issues to human agents.\n",
      "6. **Financial Analysis and Predictive Modeling**: Generative AI can be used to analyze large datasets and generate predictions about future financial performance, helping businesses make more informed investment decisions.\n",
      "7. **Sales Enablement**: Generative AI can be used to generate personalized sales pitches, product demos, and other sales materials that can help businesses improve their sales performance.\n",
      "8. **Human Resources**: Generative AI can be used to analyze employee data and generate recommendations for talent development, career advancement, and recruitment.\n",
      "9. **Creative Writing and Storytelling**: Generative AI can be used to generate high-quality creative writing, such as fiction, poetry, and even entire scripts.\n",
      "10. **Data Visualization**: Generative AI can be used to create interactive and dynamic data visualizations that can help businesses communicate complex data insights more effectively.\n",
      "\n",
      "Some specific business applications of Generative AI include:\n",
      "\n",
      "* **Autonomous Customer Service**: A company like Amazon uses Generative AI-powered chatbots to provide 24/7 customer support.\n",
      "* **Automated Content Writing**: A company like Forbes uses Generative AI to generate high-quality articles and blog posts on various topics.\n",
      "* **Personalized Marketing**: A company like Coca-Cola uses Generative AI to generate personalized marketing campaigns based on customer data and behavior.\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative use cases across various industries.\n"
     ]
    }
   ],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Creation**: Generate high-quality content such as articles, social media posts, product descriptions, and even entire books using tools like language models.\n",
      "2. **Product Design**: Use generative design to create custom products, such as 3D models, logos, and packaging designs, that can be used in various industries, including fashion, aerospace, and automotive.\n",
      "3. **Marketing Automation**: Automate marketing campaigns by generating personalized emails, social media posts, and ad copy using AI-generated content.\n",
      "4. **Customer Service Chatbots**: Develop chatbots that use generative AI to respond to customer inquiries, providing 24/7 support and improving customer satisfaction.\n",
      "5. **Data Analysis**: Use generative AI to analyze large datasets, identify patterns, and predict trends, helping businesses make data-driven decisions.\n",
      "6. **Image Generation**: Generate high-quality images for marketing materials, such as product photography, social media posts, and advertisements.\n",
      "7. **Music and Audio Production**: Use generative AI to create music, sound effects, and audio tracks that can be used in various industries, including film, gaming, and advertising.\n",
      "8. **Language Translation**: Develop AI-powered translation tools that can generate accurate translations for businesses operating globally.\n",
      "9. **UX/UI Design**: Use generative design to create user interfaces (UI) and user experiences (UX) that are more intuitive and engaging.\n",
      "10. **Predictive Maintenance**: Use generative AI to analyze sensor data and predict equipment failures, reducing downtime and improving overall efficiency.\n",
      "11. **Financial Modeling**: Develop AI-powered financial models that can generate forecasts, identify trends, and optimize investment portfolios.\n",
      "12. **Supply Chain Optimization**: Use generative AI to optimize supply chain operations, predicting demand, managing inventory, and streamlining logistics.\n",
      "\n",
      "Some specific examples of businesses using Generative AI include:\n",
      "\n",
      "* IBM's AI-generated music for film and TV soundtracks\n",
      "* Amazon's AI-powered product recommendations\n",
      "* Google's AI-generated images for advertising\n",
      "* Salesforce's AI-powered customer service chatbots\n",
      "* Accenture's AI-powered financial modeling and optimization services\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative uses in various industries.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Generation**: AI-powered tools can generate high-quality content such as blog posts, social media posts, product descriptions, and more. This helps reduce content creation time and costs.\n",
      "2. **Virtual Customer Service Reps**: Chatbots and virtual assistants powered by Generative AI can provide 24/7 customer support, answering frequently asked questions, and helping customers with simple inquiries.\n",
      "3. **Image and Video Creation**: Generative AI can create high-quality images and videos for advertising, marketing, and product visuals. This includes custom illustrations, graphics, and animations.\n",
      "4. **Product Design**: AI-powered design tools can help generate product concepts, designs, and 3D models, streamlining the product development process.\n",
      "5. **Music Composition**: Generative AI music composition tools can create original music tracks for films, TV shows, and advertisements, reducing music production costs and time.\n",
      "6. **Text Generation**: AI can generate text such as reports, proposals, and documents, helping businesses save time and resources on writing tasks.\n",
      "7. **Predictive Analytics**: Generative AI algorithms can analyze historical data to predict future trends and patterns, enabling businesses to make more informed decisions.\n",
      "8. **Personalization**: AI-powered tools can generate personalized content recommendations for customers based on their browsing history, purchase behavior, and other factors.\n",
      "9. **Data Analysis**: Generative AI can help analyze large datasets to identify trends, patterns, and insights, providing valuable business intelligence.\n",
      "10. **Marketing Automation**: Generative AI can automate marketing tasks such as social media posting, email crafting, and lead generation, freeing up human resources for more strategic activities.\n",
      "\n",
      "Industry-specific applications:\n",
      "\n",
      "1. **Finance**: Generative AI can help with financial forecasting, risk analysis, and portfolio management.\n",
      "2. **Healthcare**: AI-powered tools can generate medical content, create personalized medication recommendations, and analyze patient data to optimize treatment plans.\n",
      "3. **Education**: AI-powered adaptive learning systems can create custom educational content, grade assignments, and provide personalized feedback to students.\n",
      "4. **Supply Chain Management**: Generative AI can optimize inventory management, predict demand, and recommend logistics routes.\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect even more innovative uses cases in various industries.\n"
     ]
    }
   ],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e22da-b891-41f6-9ac9-bd0c0a5f4f44",
   "metadata": {},
   "source": [
    "## Are you confused about why that works?\n",
    "\n",
    "It seems strange, right? We just used OpenAI code to call Ollama?? What's going on?!\n",
    "\n",
    "Here's the scoop:\n",
    "\n",
    "The python class `OpenAI` is simply code written by OpenAI engineers that makes calls over the internet to an endpoint.  \n",
    "\n",
    "When you call `openai.chat.completions.create()`, this python code just makes a web request to the following url: \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "Code like this is known as a \"client library\" - it's just wrapper code that runs on your machine to make web requests. The actual power of GPT is running on OpenAI's cloud behind this API, not on your computer!\n",
    "\n",
    "OpenAI was so popular, that lots of other AI providers provided identical web endpoints, so you could use the same approach.\n",
    "\n",
    "So Ollama has an endpoint running on your local box at http://localhost:11434/v1/chat/completions  \n",
    "And in week 2 we'll discover that lots of other providers do this too, including Gemini and DeepSeek.\n",
    "\n",
    "And then the team at OpenAI had a great idea: they can extend their client library so you can specify a different 'base url', and use their library to call any compatible API.\n",
    "\n",
    "That's it!\n",
    "\n",
    "So when you say: `ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')`  \n",
    "Then this will make the same endpoint calls, but to Ollama instead of OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## Also trying the amazing reasoning model DeepSeek\n",
    "\n",
    "Here we use the version of DeepSeek-reasoner that's been distilled to 1.5B.  \n",
    "This is actually a 1.5B variant of Qwen that has been fine-tuned using synethic data generated by Deepseek R1.\n",
    "\n",
    "Other sizes of DeepSeek are [here](https://ollama.com/library/deepseek-r1) all the way up to the full 671B parameter version, which would use up 404GB of your drive and is far too large for most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I've got this question about LLMs, specifically asking for definitions of neural networks, attention, and transformers. Hmm, let me start by recalling everything I know regarding LLMs before diving into each concept individually.\n",
      "\n",
      "Alright, first off, what is an LLM? I think it stands for Large Language Model. From what I remember, traditional bigrams are used in language models to predict the next word or character, but LLMs go beyond that by handling more complex tasks like text generation, understanding various domains, and even doing reasoning.\n",
      "\n",
      "Now, moving on to neural networks. I understand they're inspired by the structure of the brain, using neurons and synapses for information processing. Each layer in a network processes previous data through weights and biases until it forms a decision or prediction. For LLMs, this involves multiple layers handling context and making predictions. That makes sense because each step the model takes can be weighted differently.\n",
      "\n",
      "Attention is another key part I've heard about. It's supposed to focus on relevant parts of input text. Unlike bigrams, attention allows the model to prioritize which words are important in generating a response or identifying specific concepts. So without attention, it might mix up information from random places.\n",
      "\n",
      "The transformer itself is a more recent concept. From what I gather, transformers use attention all throughout. Each position processes different positions and attends to various representations of other tokens simultaneously. This allows for a lot of parallel processing during inference, which is why models can handle longer sequences quickly. It's pretty efficient compared to recurrent neural networks.\n",
      "\n",
      "Putting it all together, the LLM operates by taking input text and using multiple layers in a deep network (which builds up features through each layer). Each layer processes these features further. But where that feature processing happens? That's where attention comes into play, directing the model's focus on important parts of the input, possibly in real-time while building features or at inference time when generating outputs.\n",
      "\n",
      "Wait, but aren't all LLM models based onTransformer architectures? I'm not entirely sure about that. Maybe other frameworks like RoBERTa or others use different structures. But yeah, many do seem to rely on transformer mechanisms.\n",
      "\n",
      "Also, thinking about how attention and transformers work together: during training, the model processes each token through multiple layers, each time allowing for attention across the input but in real-time while building the features. At inference, once all the layers have processed the data (or most of them by then), attention is used to output a response quickly.\n",
      "\n",
      "So if someone were to implement an LLM from scratch without going through existing frameworks, they might attempt to design such a model, integrating these components step by step. But in practice, people use standard transformers built on top of deep learning architectures with attention mechanisms for processing inputs.\n",
      "\n",
      "I wonder how this compares across different LLM models. For example, BERT uses a large transformer like RoBERTa or T5 which is designed to handle multilingual tasks efficiently thanks to their architecture and attention mechanisms. Others might have more specialized structures but similar principles applied in their layers.\n",
      "\n",
      "In summary, understanding these components means grasping how they work together seamlessly in making language models powerful for various tasks beyond just predicting the next word.\n",
      "</think>\n",
      "\n",
      "**Definitions of Key Concepts Behind Large Language Models (LLMs):**\n",
      "\n",
      "1. **Neural Network:**\n",
      "   A neural network is a computational model inspired by the structure and function of the human brain, composed of layers connected nodes (neurons) that process and transmit information. Each node receives input, processes it using weights and biases, and applies an activation function to produce output. In the context of LLMs, these networks are deep feedforward neural networks that learn hierarchical representations of text data.\n",
      "\n",
      "2. **Attention:**\n",
      "   Attention is a mechanism designed to identify the most relevant parts of input data in real-time or simultaneously during processing or generation. It allows models to focus on specific aspects while integrating information from various positions, enhancing understanding and performance.\n",
      "\n",
      "3. **Transformer:**\n",
      "   The transformer architecture introduces cross-layer interactions, enabling each position within a model (input, hidden layers, or output) to process different representations concurrently. This feature facilitates efficient parallel computation during both training and inference, leading to models capable of handling long sequences effectively.\n",
      "\n",
      "These components work together harmoniously in LLMs, functioning as the core algorithms that enable vast capabilities such as text generation, understanding diverse domains, and reasoning.\n"
     ]
    }
   ],
   "source": [
    "# This may take a few minutes to run! You should then see a fascinating \"thinking\" trace inside <think> tags, followed by some decent definitions\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de38216-6d1c-48c4-877b-86d403f4e0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
